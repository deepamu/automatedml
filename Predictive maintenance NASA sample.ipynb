{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Microsoft Azure AutoML Demo"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Purpose and Challenge"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The purpose of this notebook is for the user to build and deploy a Machine Learning (ML) application using Azure Machine Learning (AML) Service which is in preview, end-2-end. The challenge we will tackle is a simple predictive maintenance solution.\n\nThis notebook has the complete code to load, prep, train and deploy the model. We chose a small public data set for this demo so as to run the entire process in only few minutes. Please note that AML Service is in preview and is being updated constantly to address any issues and add new functionality. \n\nAlso, this notebook has been tested using Azure Notebooks Service (preview) so as to do the demo all on Azure!!!\n\nFollowing are the high level steps:\n\n1. Acquire and Prepare Data\n2. Automated ML\n3. Deploy Model\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 1. Acquire and Prepare Data\nFor this notebook, we will use the NASA Prognostics Center's Turbo-Fan Failure dataset.  It is located here: https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We have it as .txt file in the same folder. We read it into a Pandas DataFrame.\nNote the headers were not in the space seperated txt file, so we assign them from the ReadMe in the zip file. In pandas we use read_csv with the delimiter option, even with a space delimited file."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\ntrain = pd.read_csv(\"train_FD001.txt\", delimiter=\"\\s|\\s\\s\", index_col=False, engine='python', names=['unit','cycle','os1','os2','os3','sm1','sm2','sm3','sm4','sm5','sm6','sm7','sm8','sm9','sm10','sm11','sm12','sm13','sm14','sm15','sm16','sm17','sm18','sm19','sm20','sm21'])",
      "execution_count": 91,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Take a quick look at the data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train.head(5)",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 92,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit</th>\n      <th>cycle</th>\n      <th>os1</th>\n      <th>os2</th>\n      <th>os3</th>\n      <th>sm1</th>\n      <th>sm2</th>\n      <th>sm3</th>\n      <th>sm4</th>\n      <th>sm5</th>\n      <th>...</th>\n      <th>sm12</th>\n      <th>sm13</th>\n      <th>sm14</th>\n      <th>sm15</th>\n      <th>sm16</th>\n      <th>sm17</th>\n      <th>sm18</th>\n      <th>sm19</th>\n      <th>sm20</th>\n      <th>sm21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.0007</td>\n      <td>-0.0004</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>641.82</td>\n      <td>1589.70</td>\n      <td>1400.60</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>521.66</td>\n      <td>2388.02</td>\n      <td>8138.62</td>\n      <td>8.4195</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.06</td>\n      <td>23.4190</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0019</td>\n      <td>-0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.15</td>\n      <td>1591.82</td>\n      <td>1403.14</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>522.28</td>\n      <td>2388.07</td>\n      <td>8131.49</td>\n      <td>8.4318</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.00</td>\n      <td>23.4236</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>-0.0043</td>\n      <td>0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1587.99</td>\n      <td>1404.20</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>522.42</td>\n      <td>2388.03</td>\n      <td>8133.23</td>\n      <td>8.4178</td>\n      <td>0.03</td>\n      <td>390</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.95</td>\n      <td>23.3442</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.0007</td>\n      <td>0.0000</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1582.79</td>\n      <td>1401.87</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>522.86</td>\n      <td>2388.08</td>\n      <td>8133.83</td>\n      <td>8.3682</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.88</td>\n      <td>23.3739</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>-0.0019</td>\n      <td>-0.0002</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.37</td>\n      <td>1582.85</td>\n      <td>1406.22</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>522.19</td>\n      <td>2388.04</td>\n      <td>8133.80</td>\n      <td>8.4294</td>\n      <td>0.03</td>\n      <td>393</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.90</td>\n      <td>23.4044</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>",
            "text/plain": "   unit  cycle     os1     os2    os3     sm1     sm2      sm3      sm4  \\\n0  1     1     -0.0007 -0.0004  100.0  518.67  641.82  1589.70  1400.60   \n1  1     2      0.0019 -0.0003  100.0  518.67  642.15  1591.82  1403.14   \n2  1     3     -0.0043  0.0003  100.0  518.67  642.35  1587.99  1404.20   \n3  1     4      0.0007  0.0000  100.0  518.67  642.35  1582.79  1401.87   \n4  1     5     -0.0019 -0.0002  100.0  518.67  642.37  1582.85  1406.22   \n\n     sm5   ...       sm12     sm13     sm14    sm15  sm16  sm17  sm18   sm19  \\\n0  14.62   ...     521.66  2388.02  8138.62  8.4195  0.03  392   2388  100.0   \n1  14.62   ...     522.28  2388.07  8131.49  8.4318  0.03  392   2388  100.0   \n2  14.62   ...     522.42  2388.03  8133.23  8.4178  0.03  390   2388  100.0   \n3  14.62   ...     522.86  2388.08  8133.83  8.3682  0.03  392   2388  100.0   \n4  14.62   ...     522.19  2388.04  8133.80  8.4294  0.03  393   2388  100.0   \n\n    sm20     sm21  \n0  39.06  23.4190  \n1  39.00  23.4236  \n2  38.95  23.3442  \n3  38.88  23.3739  \n4  38.90  23.4044  \n\n[5 rows x 26 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Our dataset has a number of units in it, with each engine flight listed as a cycle. The cycles count up until the engine fails. What we would like to predict is the no. of cycles until failure. \nSo we need to calculate a new column called RUL, or Remaining Useful Life.  It will be the last cycle value minus each cycle value per unit."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Assign ground truth\ndef assignrul(df):\n    maxi = df['cycle'].max()\n    df['rul'] = maxi - df['cycle']\n    return df\n    \n\ntrain_new = train.groupby('unit').apply(assignrul)\n\ntrain_new.columns",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 93,
          "data": {
            "text/plain": "Index(['unit', 'cycle', 'os1', 'os2', 'os3', 'sm1', 'sm2', 'sm3', 'sm4', 'sm5',\n       'sm6', 'sm7', 'sm8', 'sm9', 'sm10', 'sm11', 'sm12', 'sm13', 'sm14',\n       'sm15', 'sm16', 'sm17', 'sm18', 'sm19', 'sm20', 'sm21', 'rul'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now our dataframe has the 'RUL' column.  Predicting this value will be the objective of this exercise."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_new.head(5)",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 94,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit</th>\n      <th>cycle</th>\n      <th>os1</th>\n      <th>os2</th>\n      <th>os3</th>\n      <th>sm1</th>\n      <th>sm2</th>\n      <th>sm3</th>\n      <th>sm4</th>\n      <th>sm5</th>\n      <th>...</th>\n      <th>sm13</th>\n      <th>sm14</th>\n      <th>sm15</th>\n      <th>sm16</th>\n      <th>sm17</th>\n      <th>sm18</th>\n      <th>sm19</th>\n      <th>sm20</th>\n      <th>sm21</th>\n      <th>rul</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>-0.0007</td>\n      <td>-0.0004</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>641.82</td>\n      <td>1589.70</td>\n      <td>1400.60</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>2388.02</td>\n      <td>8138.62</td>\n      <td>8.4195</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.06</td>\n      <td>23.4190</td>\n      <td>191</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.0019</td>\n      <td>-0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.15</td>\n      <td>1591.82</td>\n      <td>1403.14</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>2388.07</td>\n      <td>8131.49</td>\n      <td>8.4318</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>39.00</td>\n      <td>23.4236</td>\n      <td>190</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>-0.0043</td>\n      <td>0.0003</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1587.99</td>\n      <td>1404.20</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>2388.03</td>\n      <td>8133.23</td>\n      <td>8.4178</td>\n      <td>0.03</td>\n      <td>390</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.95</td>\n      <td>23.3442</td>\n      <td>189</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>0.0007</td>\n      <td>0.0000</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.35</td>\n      <td>1582.79</td>\n      <td>1401.87</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>2388.08</td>\n      <td>8133.83</td>\n      <td>8.3682</td>\n      <td>0.03</td>\n      <td>392</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.88</td>\n      <td>23.3739</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>-0.0019</td>\n      <td>-0.0002</td>\n      <td>100.0</td>\n      <td>518.67</td>\n      <td>642.37</td>\n      <td>1582.85</td>\n      <td>1406.22</td>\n      <td>14.62</td>\n      <td>...</td>\n      <td>2388.04</td>\n      <td>8133.80</td>\n      <td>8.4294</td>\n      <td>0.03</td>\n      <td>393</td>\n      <td>2388</td>\n      <td>100.0</td>\n      <td>38.90</td>\n      <td>23.4044</td>\n      <td>187</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 27 columns</p>\n</div>",
            "text/plain": "   unit  cycle     os1     os2    os3     sm1     sm2      sm3      sm4  \\\n0  1     1     -0.0007 -0.0004  100.0  518.67  641.82  1589.70  1400.60   \n1  1     2      0.0019 -0.0003  100.0  518.67  642.15  1591.82  1403.14   \n2  1     3     -0.0043  0.0003  100.0  518.67  642.35  1587.99  1404.20   \n3  1     4      0.0007  0.0000  100.0  518.67  642.35  1582.79  1401.87   \n4  1     5     -0.0019 -0.0002  100.0  518.67  642.37  1582.85  1406.22   \n\n     sm5 ...      sm13     sm14    sm15  sm16  sm17  sm18   sm19   sm20  \\\n0  14.62 ...   2388.02  8138.62  8.4195  0.03  392   2388  100.0  39.06   \n1  14.62 ...   2388.07  8131.49  8.4318  0.03  392   2388  100.0  39.00   \n2  14.62 ...   2388.03  8133.23  8.4178  0.03  390   2388  100.0  38.95   \n3  14.62 ...   2388.08  8133.83  8.3682  0.03  392   2388  100.0  38.88   \n4  14.62 ...   2388.04  8133.80  8.4294  0.03  393   2388  100.0  38.90   \n\n      sm21  rul  \n0  23.4190  191  \n1  23.4236  190  \n2  23.3442  189  \n3  23.3739  188  \n4  23.4044  187  \n\n[5 rows x 27 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "First note that the sensor measurements do seem to be changing as we near 0 RUL. This implies that we should be able to make a model that will be useful enough for business value.\n\nWe are now ready to train a model on this data using Automated ML."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3. automated ML"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Here we utilize Azure's AutoML package to automate the scaling of the sensors, selection of sensors, and automatically train and evaluate many different types of ML models."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Import Azure ML libs for automated ML"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import logging\nimport os\nimport random\nimport time\n\nfrom matplotlib import pyplot as plt\nfrom matplotlib.pyplot import imshow\nimport numpy as np\nimport pandas as pd\n\nimport azureml.core\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.workspace import Workspace\nfrom azureml.train.automl import AutoMLConfig\nfrom azureml.train.automl.run import AutoMLRun\nfrom azureml.widgets import RunDetails\nfrom azureml.core.model import Model",
      "execution_count": 95,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Provide your Machine Learning Workspace credentials to run AutoML. You will need to perform Microsoft's MFA. Please follow the manual auth instructions."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "subscription_id = \"<Your SubscriptionId>\" #you should be owner or contributor\nresource_group = \"<Resource group - new or existing>\" #you should be owner or contributor\nworkspace_name = \"<workspace to be created>\" #your workspace name\nworkspace_region = \"<azureregion>\" #your region\n\n#Example here, use your own\nsubscription_id = \"381b38e9-9840-4719-a5a0-61d9585e1e91\" #you should be owner or contributor\nresource_group = \"automl_nasa_newrg\" #you should be owner or contributor\nworkspace_name = \"automatedml_nasa_aznb\" #your workspace name\nworkspace_region = \"eastus2\" #your region",
      "execution_count": 96,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Create Azure ML workspace"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Import the Workspace class and check the Azure ML SDK version.\nfrom azureml.core import Workspace\n\nws = Workspace.create(name = workspace_name,\n                      subscription_id = subscription_id,\n                      resource_group = resource_group, \n                      location = workspace_region,                      \n                      exist_ok=True)\nws.get_details()",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 97,
          "data": {
            "text/plain": "{'id': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourceGroups/automl_nasa_newrg/providers/Microsoft.MachineLearningServices/workspaces/automatedml_nasa_aznb',\n 'name': 'automatedml_nasa_aznb',\n 'location': 'eastus2',\n 'type': 'Microsoft.MachineLearningServices/workspaces',\n 'workspaceid': '38a769cf-f8b3-424c-a906-838d79ac1ad4',\n 'description': '',\n 'friendlyName': 'automatedml_nasa_aznb',\n 'creationTime': '2019-02-17T05:34:39.4332596+00:00',\n 'containerRegistry': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/automl_nasa_newrg/providers/microsoft.containerregistry/registries/automateacrpezaacbj',\n 'keyVault': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/automl_nasa_newrg/providers/microsoft.keyvault/vaults/automatekeyvaultkpirsgjr',\n 'applicationInsights': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/automl_nasa_newrg/providers/microsoft.insights/components/automateinsightsblxrzkqy',\n 'identityPrincipalId': 'c28b72a9-401c-4d06-9e08-90f98b915a95',\n 'identityTenantId': '72f988bf-86f1-41af-91ab-2d7cd011db47',\n 'identityType': 'SystemAssigned',\n 'storageAccount': '/subscriptions/381b38e9-9840-4719-a5a0-61d9585e1e91/resourcegroups/automl_nasa_newrg/providers/microsoft.storage/storageaccounts/automatestorageacsdgcie'}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Write config to cluster"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace\n\nws = Workspace(workspace_name = workspace_name,\n               subscription_id = subscription_id,\n               resource_group = resource_group)\n\n# Persist the subscription id, resource group name, and workspace name in aml_config/config.json.\nws.write_config()",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Wrote the config file config.json to: /home/nbuser/library/aml_config/config.json\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Define the experiment name"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Choose a name for the experiment and specify the project folder.\nexperiment_name = 'automl-predictive-rul'\nproject_folder = './sample_projects/automl-demo-predmain'\n\nexperiment = Experiment(ws, experiment_name)\n\noutput = {}\noutput['SDK version'] = azureml.core.VERSION\noutput['Subscription ID'] = ws.subscription_id\noutput['Workspace Name'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\noutput['Project Directory'] = project_folder\noutput['Experiment Name'] = experiment.name\npd.set_option('display.max_colwidth', -1)\npd.DataFrame(data = output, index = ['']).T",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 99,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Experiment Name</th>\n      <td>automl-predictive-rul</td>\n    </tr>\n    <tr>\n      <th>Location</th>\n      <td>eastus2</td>\n    </tr>\n    <tr>\n      <th>Project Directory</th>\n      <td>./sample_projects/automl-demo-predmain</td>\n    </tr>\n    <tr>\n      <th>Resource Group</th>\n      <td>automl_nasa_newrg</td>\n    </tr>\n    <tr>\n      <th>SDK version</th>\n      <td>1.0.10</td>\n    </tr>\n    <tr>\n      <th>Subscription ID</th>\n      <td>381b38e9-9840-4719-a5a0-61d9585e1e91</td>\n    </tr>\n    <tr>\n      <th>Workspace Name</th>\n      <td>automatedml_nasa_aznb</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                         \nExperiment Name    automl-predictive-rul                 \nLocation           eastus2                               \nProject Directory  ./sample_projects/automl-demo-predmain\nResource Group     automl_nasa_newrg                     \nSDK version        1.0.10                                \nSubscription ID    381b38e9-9840-4719-a5a0-61d9585e1e91  \nWorkspace Name     automatedml_nasa_aznb                 "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Create training data"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# put training data into X and Y arrays\nX_train = train_new.iloc[:,2:26].values\ny_train = train_new.iloc[:,26:27].values.astype(int).flatten()",
      "execution_count": 100,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Format data into arrays that AutoML will use to train models.  Below is one row of X and Y as an example."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_train[0]",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 101,
          "data": {
            "text/plain": "array([-7.00000e-04, -4.00000e-04,  1.00000e+02,  5.18670e+02,\n        6.41820e+02,  1.58970e+03,  1.40060e+03,  1.46200e+01,\n        2.16100e+01,  5.54360e+02,  2.38806e+03,  9.04619e+03,\n        1.30000e+00,  4.74700e+01,  5.21660e+02,  2.38802e+03,\n        8.13862e+03,  8.41950e+00,  3.00000e-02,  3.92000e+02,\n        2.38800e+03,  1.00000e+02,  3.90600e+01,  2.34190e+01])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_train[0]",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 102,
          "data": {
            "text/plain": "191"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Enable Telemetry"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.telemetry import set_diagnostics_collection\nset_diagnostics_collection(send_diagnostics = True)",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Turning diagnostics collection on. \n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now we are ready to configure automated ML.  We provide necessary information on: what we want to predict, what accuracy metric we want to use, how many models we want to try, and many other parameters.  AutoML will also automatically scale the data for us."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Configure Automated ML\n\nYou can use these params.\n\n|Property|Description|\n|-|-|\n|**task**|classification or regression|\n|**primary_metric**|This is the metric that you want to optimize. Classification supports the following primary metrics: <br><i>accuracy</i><br><i>AUC_weighted</i><br><i>average_precision_score_weighted</i><br><i>norm_macro_recall</i><br><i>precision_score_weighted</i>|\n|**primary_metric**|This is the metric that you want to optimize. Regression supports the following primary metrics: <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>|\n|**iteration_timeout_minutes**|Time limit in minutes for each iteration.|\n|**iterations**|Number of iterations. In each iteration AutoML trains a specific pipeline with the data.|\n|**n_cross_validations**|Number of cross validation splits.|\n|**X**|(sparse) array-like, shape = [n_samples, n_features]|\n|**y**|(sparse) array-like, shape = [n_samples, ], [n_samples, n_classes]<br>Multi-class targets. An indicator matrix turns on multilabel classification. This should be an array of integers.|\n|**path**|Relative path to the project folder. AutoML stores configuration files for the experiment under this folder. You can specify a new empty folder.|\n|**preprocess**|set this to True to enable pre-processing of data eg. string to numeric using one-hot encoding|\n|**exit_score**|Target score for experiment. It is associated with the metric. eg. exit_score=0.995 will exit experiment after that|"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "##Local compute \nAutoml_config = AutoMLConfig(task = 'regression',\n                             primary_metric = 'r2_score',\n                             iteration_timeout_minutes = 5,\n                             iterations = 10,\n                             n_cross_validations = 3,\n                             max_cores_per_iteration = 1,\n                             preprocess = False,\n                             experiment_exit_score = 0.985,\n                             #blacklist_models = ['kNN','LinearSVM', 'ExtremeRandomTrees', 'RandomForestRegressor'],\n                             whitelist_models = ['ExtremeRandomTrees','ElasticNet','LightGBM'],\n                             X = X_train,\n                             y = y_train,\n                             debug_log = 'automl_errors.log',\n                             verbosity=logging.ERROR,\n                             path=project_folder)",
      "execution_count": 123,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Finally we are ready to launch AutoML.  This step can take many minutes, but AutoML will give you updates as models are trained and evaluated by the metric we specified above.  AutoML also let us know which scaling method was used.  The information from each ML model training will be stored in the Experiment section of the ML Workspace, where we can review it through Azure Portal."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Train multiple models using AutoML\nexperiment=Experiment(ws, experiment_name)\nlocal_run = experiment.submit(Automl_config, show_output=True)",
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Running on local machine\nParent Run ID: AutoML_7209ff4c-5775-40bc-90f0-c02b4440ea1c\n*******************************************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nTRAINFRAC: Fraction of the training data to train on.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n*******************************************************************************************************************\n\n ITERATION   PIPELINE                                       TRAINFRAC  DURATION      METRIC      BEST\n         0   SparseNormalizer ExtremeRandomTrees            1.0000     0:02:58       0.6355    0.6355\n         1   StandardScalerWrapper LightGBM                 1.0000     0:02:19       0.6252    0.6355\n         2   StandardScalerWrapper ExtremeRandomTrees       1.0000     0:02:40       0.5458    0.6355\n         3   MinMaxScaler ExtremeRandomTrees                1.0000     0:02:05       0.5578    0.6355\n         4   StandardScalerWrapper ExtremeRandomTrees       1.0000     0:02:09       0.5869    0.6355\n         5   StandardScalerWrapper ElasticNet               1.0000     0:01:44       0.5786    0.6355\n         6   SparseNormalizer LightGBM                      1.0000     0:02:32       0.6313    0.6355\n         7   StandardScalerWrapper ElasticNet               1.0000     0:01:36       0.5787    0.6355\n         8   StandardScalerWrapper LightGBM                 1.0000     0:06:56       0.5903    0.6355\n         9   Ensemble                                       1.0000     0:04:37       0.6311    0.6355\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Widget UX"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "RunDetails(local_run).show()",
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b57a918b39b54843a5e15ef7a586fefb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'sd…"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We now get the best model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# find the run with the highest accuracy value.\nbest_run, fitted_model = local_run.get_output()\nprint(best_run)",
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Run(Experiment: automl-predictive-rul,\nId: AutoML_7209ff4c-5775-40bc-90f0-c02b4440ea1c_0,\nType: None,\nStatus: Completed)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 3. Deploy Model"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# register best model in workspace\ndescription = 'AutoML-RUL-Regression-20190213'\ntags = None\nlocal_run.register_model(description=description, tags=tags)\nlocal_run.model_id # Use this id to deploy the model as a web service in Azure",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Registering model AutoML7209ff4c5best\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 127,
          "data": {
            "text/plain": "'AutoML7209ff4c5best'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "After we register the model in our ML Workspace, it should be visible in Azure Portal.\n\nNow we want to deploy the model as a REST API that we can feed a row or rows of \"X\" data to, and return the predicted 'RUL' value.  To accomplish this, we will build a container image in our AML Workspace and deploy that image as a Container instance in Azure's ACI service.  We will then obtain an IP address where we can submit data and receive back the predicted 'RUL' value.\n\nThere are 3 things we need: \n1. A score.py file that contains the init() and run() functions with instructions on how to load and socre with the model\n2. A myenv.yml file that contains information on the python environment in which the model needs to run\n3. Configurations for our images and our services, using functions provided by AzureML service.\n\nThe cells below help you set these up.   You will need to use the registered model name provided by the cell above."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile score.py\n# Scoring Script\nimport json\nimport numpy as np\nimport os\nimport pickle\nfrom sklearn.externals import joblib\nfrom sklearn.linear_model import LogisticRegression\n\nfrom azureml.core.model import Model\n\nimport azureml.train.automl\n\ndef init():\n    global model\n    # retreive the path to the model file using the model name\n    model_path = Model.get_model_path('AutoML7209ff4c5best')\n    print(model_path)\n    model = joblib.load(model_path)\n    \n\ndef run(raw_data):\n    # grab and prepare the data\n    data = (np.array(json.loads(raw_data)['data'])).reshape(1,-1)\n    # make prediction\n    y_hat = model.predict(data)\n    return json.dumps(y_hat.tolist())",
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Overwriting score.py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.conda_dependencies import CondaDependencies\n\nmyenv = CondaDependencies.create(conda_packages=['numpy','scikit-learn','lightgbm'], pip_packages=['azureml-sdk[automl]'])\n\nconda_env_file_name = 'myenv.yml'\nmyenv.save_to_file('.', conda_env_file_name)",
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 129,
          "data": {
            "text/plain": "'myenv.yml'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.conda_dependencies import CondaDependencies \n\nmyenv = CondaDependencies()\nmyenv.add_conda_package(\"scikit-learn\")\n\nwith open(\"myenv.yml\",\"w\") as f:\n    f.write(myenv.serialize_to_string())",
      "execution_count": 130,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "with open(\"myenv.yml\",\"r\") as f:\n    print(f.read())",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": "# Conda environment specification. The dependencies defined in this file will\n# be automatically provisioned for runs with userManagedDependencies=False.\n\n# Details about the Conda environment file format:\n# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n\nname: project_environment\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2\n\n- pip:\n    # Required packages for AzureML execution, history, and data preparation.\n  - azureml-defaults\n- scikit-learn\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "*If the above file does not show \"- azureml-train-automl\" in the pip section, the you need to add it manually*\n\nNow configure the webservice."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice\n\naciconfig = AciWebservice.deploy_configuration(cpu_cores=2, \n                                               memory_gb=2, \n                                               tags={\"data\": \"RUL\",  \"method\" : \"sklearn\"}, \n                                               description='Predict RUL with Azure AutoML')",
      "execution_count": 132,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Finally, configure the container image and deploy the service. Make sure the filenames match, your Workspace is in variable ws, and your model name is correct. It will create your containter image and deploy it as a webservice.\n\nThis process can take up to 10 minutes, so please be patient. You can check the progress bar periodically ..."
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%time\nfrom azureml.core.webservice import Webservice\nfrom azureml.core.image import ContainerImage\n\n# configure the image\nimage_config = ContainerImage.image_configuration(execution_script=\"score.py\", \n                                                  runtime=\"python\", \n                                                  conda_file=\"myenv.yml\")\n\nservice = Webservice.deploy_from_model(workspace=ws,\n                                       name='automl-rul-regress5',\n                                       deployment_config=aciconfig,\n                                       models=['AutoML7209ff4c5best:1'],\n                                       image_config=image_config)\n\nservice.wait_for_deployment(show_output=True)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Creating image\nImage creation operation finished for image automl-rul-regress5:1, operation \"Succeeded\"\nCreating service\nRunning...............",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Just as a check, we can retrieve the URI for the scoring function."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(service.scoring_uri)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's check to see if the service is working.  Here we submit a single row of data from X_train to see if it returns a reasonable prediction."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import requests\nimport json\n\n# send a random row from the test set to score\n#random_index = np.random.randint(0, len(X_train)-1)\ninput_data = \"{\\\"data\\\": \" + str(list(X_train[0].reshape(1,-1)[0])) + \"}\"\n\nheaders = {'Content-Type':'application/json'}\n\n# for AKS deployment you'd need to the service key in the header as well\n# api_key = service.get_key()\n# headers = {'Content-Type':'application/json',  'Authorization':('Bearer '+ api_key)} \n\nresp = requests.post(service.scoring_uri, input_data, headers=headers)\n\nprint(\"POST to url\", service.scoring_uri)\nprint(\"input data:\", input_data)\nprint(\"label:\", y_train[0:1])\nprint(\"prediction:\", resp.text)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Here we see one engine evolving through many flights, or cycles.  As we approach failure, the rul declines to zero, as does the prediction.  This is a good example of how the predictive model can assist in estimate the future failure of the engine.\n\nNote that the model does not perform well at high rul.  This is an acceptable outcome as the engine is far from failure."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To avoid any run-away Azure costs, we always delete un-necessary services when we are done."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "service.delete()",
      "execution_count": 117,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}